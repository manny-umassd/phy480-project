{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000afa7b-a065-445d-a941-8c2d1f14b00e",
   "metadata": {},
   "source": [
    "# Orbital Orchestra of the Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a4a51-56b7-40c8-8bd0-81555aa497a6",
   "metadata": {},
   "source": [
    "## Using a Neural Network to Observe the N-Body Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab787b65-3fde-4608-9fb0-f2a158ca6857",
   "metadata": {},
   "source": [
    "### !!! FOREWARNING, READ BEFORE YOU RUN !!!\n",
    "I have not tested the effects of running all three scripts at once using Jupyter, my intent of this document is to be documentation, not the main scripts to run. I highly recommend downloading the scripts, adjusting the filepath to your own selected path in each script, and run them separately. To properly execute script 2 you may need decent hardware, a way to cool your hardware, and plenty of time for running a few thousand training sessions. I hope the exclamations caught your attention. Ignoring my warning is your choice, if you choose to do so you agree to whatever responsibility may come about. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c54e00-c5e3-4b67-8903-6228369754de",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Let's start with how this project originally came to be. Astrophysics is the topic that interests me the most when it comes to physics. When it comes to the cosmos, I can't help but marvel at the size of literally everything, and how everything just seamlessly works together. The way we as people challenge this final frontier of outer space with what we can while only being able to observe just so much of it. I tend to dream of being involved in future missions in some capacity, so much so that I'd think of imaginary flight systems. Thoughts of GPS systems came to mind as well, I learned that they use trilateration to calculate a device's at regular intervals down here on Earth. That thought train ran to how could we implement a GPS system way out there? Rather, how do we keep track of various space objects as they move in various directions along our flight paths? This thought train is what initially led me to choose a project relating to chapter 4 of \"Computational Modeling and Visualization of Physical Systems\", the text written by and provided in Professor Wang's Computational Physics module, where the chapter looks at planetary motion and n-body simulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97d658-82b8-45f9-b6f7-ad4ccc3d5c9c",
   "metadata": {},
   "source": [
    "However, this past summer hit me with a different sort of reality. As I worked on my job search for post-graduation, I received some feedback for my applications. I would not be considered for my lack of AI and machine learning skills. My plan was then to use this project to gain that skill, yet I still wanted to work on an n-body simulation. Hence this topic came to be. I would merge the two and use machine learning to predict orbits, essentially letting me work on that simulation and gain that skill. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccfe1c-df4c-487d-88b0-d4b1f2b665ff",
   "metadata": {},
   "source": [
    "We begin the three-body simulation of the Sun, the Earth, and Jupiter below, a modification of the Earth-Sun system featured in program 4.1 and figure 4.1 of the text. \n",
    "Original modifications included a Python 3.x conversion, updating the format and modules used, and the addition of the rest of the planets in our solar system. For the sake of this project and future model training, all planets except Earth and Jupiter were removed, but their data is stored along with all the scripts made in my github. Since the original modified program contained all planets, please assume these scripts were made with their potential reinclusion in mind. They were, with the process only requiring a pasting from the full planet data library into the 'bodies' dictionary for the desired celestial object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074f03c3-618b-4e59-99f9-c7068bb6800c",
   "metadata": {},
   "source": [
    "### Section 1: N-body Simulation (AKA Solar System Sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2aafd-d76f-436c-aa38-82aec5e74d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from vpython import vector, mag, sphere, canvas, rate, textures, color  #Replaces visual module, used to generate the scene and for vector functions\n",
    "import csv  #Used for saving data in a spreadsheet\n",
    "import os   #Used for file system functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7041c-6875-40a7-a0e0-0e38a8fa9b69",
   "metadata": {},
   "source": [
    "We'll import numpy for numerical functions such as including $\\pi$, and select functions from vpython for work in 3D space.\n",
    "'vector' allows the use of vectors and 'mag' allows the collection of the magnitude of those vectors, which is helpful for tasks like obtaining distances between bodies. 'sphere', 'canvas', 'textures', 'color' were needed to create the 3D visual scene, the objects, and give them color or, solely in Earth's case, a texture. 'rate' allows the controlling of simulation speed. \n",
    "\n",
    "csv was imported so that I could export the data collected on the planetary motion into a spreadsheet that would be used to train my model. OS was imported to use a certain directory throughout all scripts, have files written or data saved or pulled, save the model, retrieve the model. All done through the same directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c150ba-bbb6-44bc-9831-074ff9a9b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = [\n",
    "   {\n",
    "        'name': 'Sun',\n",
    "        'mass': 1.0,  #In solar masses\n",
    "        'pos': vector(0, 0, 0),  #Initial position, in AU\n",
    "        'vel': vector(0, 0, 0),  #Initial velocity, in AU/yr\n",
    "        'radius': 0.2,           #Size of sphere, visual purposes only\n",
    "        'color': color.yellow,\n",
    "        'texture': None,         #Because I wanted Earth to have the Earth texture, all bodies must have this line set to 'none' for how the bodies are called in later. Tedious but aides in simplicity later.  \n",
    "    },\n",
    "    {\n",
    "        'name': 'Earth',\n",
    "        'mass': 3.0e-6,  #In Solar masses\n",
    "        'pos': vector(1.0, 0, 0),  # Distance ~1 AU from the Sun\n",
    "        'vel': vector(0, 0, -6.179),  # Pulled from table in cpms-ch04\n",
    "        'radius': 0.1,             #Visual purposes only\n",
    "        'color': color.white,      #For blank sphere so texture can be the sphere's \"color\"\n",
    "        'texture': textures.earth, #home\n",
    "    },\n",
    "    {\n",
    "        'name': 'Jupiter',   #Chosen for it's large mass. Helps cause of perturbation on the Sun\n",
    "        'mass': 9.5e-4,      #In solar masses. All masses are pulled from the table in cpms-ch04\n",
    "        'pos': vector(5.2, 0, 0),  # Distance ~5.2 AU from the Sun\n",
    "        'vel': vector(0, 0, -2.624),  # Pulled from table in cpms-ch04\n",
    "        'radius': 0.15,\n",
    "        'color': color.orange,\n",
    "        'texture': None,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea284176-2c73-41f4-ace0-3f81cdcc6ae6",
   "metadata": {},
   "source": [
    "Above we create the list of dictionaries for each celestial body. For organization we start with the centermost object and head outward as we descend In the full list, it is the Sun, Mercury, so on up to Pluto. The structure of the dictionary is integral to the scripts. It's the format used in all scripts, and the format that the model must recognize. We start with the 'name' of the body, that will also be used to automate labeling of columns in data collection. Then we have the 'mass' of the objects in terms of Solar masses. These get recalled when working with the equations of motion later on. Moving on to initial positions and velocities, both metrics get stored in a 'vector' vector to be used later on, and their values are pulled from table 4.1, \"Properties of Kepler's orbits of the Planets\" from the text. 'Radius' for each body is an unrealistic number used only to visualize the objects when the scene renders. However, it is also in AU for those who'd wish to know. 'Color' is the color of the sphere when the scene loads, we use white for Earth so that we may view the texture I was picky about in its full glory instead of painting a deep blue over it as I did in my first several runs of the prediction simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68054110-74a4-4963-87ab-9c6c5231acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accelerations(bodies):\n",
    "    \n",
    "    # Initialize a list of accelerations with zero vectors for all mentioned bodies. (Can include others)\n",
    "    accels = [vector(0,0,0) for _ in range(len(bodies))]\n",
    "    \n",
    "    # For each pair of bodies i, j, compute gravitational acceleration contribution\n",
    "    for i in range(len(bodies)):\n",
    "        for j in range(len(bodies)):\n",
    "            if i != j: #loop works as long as the two bodies referenced aren't the same. \n",
    "                # Relative position vector from body j to i\n",
    "                rij = bodies[i]['pos'] - bodies[j]['pos']\n",
    "                dist = mag(rij)\n",
    "                # Acceleration contribution from body j on i, added to list in location for specified body.\n",
    "                accels[i] += -G * bodies[j]['mass'] * rij / (dist**3)\n",
    "    return accels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd2ff2-846c-4075-9f98-eccc3dbc168d",
   "metadata": {},
   "source": [
    "We create a function used to calculate the gravitational acceleration experienced by each body we've specified above by every other body using two 'for' loops and an 'if.. does not equal' loop to verify that we do not match two like bodies (e.g. Earth pulling on Earth, prevents non-physical results and division by zero) yet still captures the interaction of every body on each other. The outer loop goes over each body as the target body, and the inner loop goes over each body as the source of gravitational force exerted on to the target body. Only if body i does not equal body j does the rest of the function run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce78324-0631-4077-b753-d340c156ae54",
   "metadata": {},
   "source": [
    "Once i not equalling j is verified, the function computes the vector pointing from body j to body i and stores the info into 'rij', whose magnitude is computed the next line down. Finally, the acceleration of that body is then added into accels[i] which acts as the total acceleration for that body. \n",
    "Plainly, we need the accelerations as they dictate the changes in velocity as the simulation progresses through time. We use the idea that \n",
    "\n",
    "$$a_i = \\frac{F_{ij}}{m_i} = -G \\frac{m_j}{r^3_{ij}}\\mathbf{r}_{ij}$$\n",
    "\n",
    "Which is aforementioned acceleration added to accels[i]\n",
    "The function finally returns the acceleration for use later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7333cbf-0c27-4540-808e-6558eaaeddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_incremental(t, bodies, filename=\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\\\\simulation_data.csv\"):\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        # Write the header if the file doesn't exist\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            headers = [\"time\"]\n",
    "            for body in bodies:\n",
    "                #Creates the rest of the header for the .csv file (e.g Sun_x, Mercury_vz) for all bodies in order listed above.\n",
    "                headers.extend([f\"{body['name']}_x\", f\"{body['name']}_y\", f\"{body['name']}_z\",\n",
    "                                f\"{body['name']}_vx\", f\"{body['name']}_vy\", f\"{body['name']}_vz\"])\n",
    "            writer.writerow(headers)\n",
    "\n",
    "    # Append the data row to the csv file\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [t]\n",
    "        for body in bodies:\n",
    "            row.extend([body['pos'].x, body['pos'].y, body['pos'].z,\n",
    "                        body['vel'].x, body['vel'].y, body['vel'].z])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5541d3-8b85-4c01-a609-972ad379265a",
   "metadata": {},
   "source": [
    "This function was designed to save the metric data for each celestial body at every timestep of the simulation and added for the PHY 480 project. It's incremental and not a batch save at the end because initially my original modified sim ran indefinitely and I was working off of that. This method still works for what I needed, and remains unchanged even after introducing an end time to cease simulating. The variables for this function are the time step involved, the 'bodies' list for the bodies' names, position, and velocity data at time. I have thought about adding acceleration data, I think the model might benefit from the extra data, but for the sake of time that will be a future adjustment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df98df10-20c7-4bc2-9a79-248a791557a9",
   "metadata": {},
   "source": [
    "The upper loop creates the header in the event that the file doesn't exist in my specified directory. It first checks with the if not condition to see if the file exists, it does now so this is skipped, but if it didn't we'd move to the next few lines. The open function opens the file in 'W'rite mode after creating it. CSV.writer is a writer object that will convert the inputted data into strings within the file. Finally, the headers are created. The first one is for 'time', and the rest are the position in x, y, z, format then the velocities in vx, vy, vz format for each celestial body in 'bodies'. The second half, lower loop, of the function is similar to the first in structure, with a lack of file check. The second half also does not create headers, it appends the data from the simulation into the columns generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c91c53d-2e88-4030-a7ca-e4f6a525c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    \n",
    "    #Run the N-body simulation using a Leapfrog integrator and visualize it.\n",
    "    \n",
    "    # Create the scene\n",
    "    scene = canvas(title=\"N-Body Simulation\", width=800, height=600)\n",
    "    scene.autoscale = True\n",
    "    \n",
    "    # Create spheres for each body for visualization\n",
    "    for b in bodies:\n",
    "        b['obj'] = sphere(\n",
    "            pos=b['pos'],\n",
    "            radius=b['radius'],\n",
    "            color=b['color'],\n",
    "            texture=b['texture'],\n",
    "            make_trail=True,\n",
    "            retain=5000  # Keep a long trail\n",
    "        )\n",
    "    \n",
    "    # Time parameters\n",
    "    t = 0.0        # Start time\n",
    "    h = 0.001       # Timestep in years\n",
    "    simulation_duration = 10.0  # Total simulation duration in years\n",
    "    data = []       # Storage for simulation data\n",
    "    \n",
    "    # Initial accelerations\n",
    "    accels = compute_accelerations(bodies)\n",
    "    \n",
    "    # Compute half-step velocities for leapfrog integrator\n",
    "    for i, b in enumerate(bodies):\n",
    "        # v_half = v + 0.5 * a * h\n",
    "        b['v_half'] = b['vel'] + 0.5 * accels[i] * h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5860a9-1713-42e3-8868-6bcd3c9e0ecc",
   "metadata": {},
   "source": [
    "The goal of this function is as commented above. Run the simulation using a Leapfrog Integrator and visualize it. Though now we have the added caveat of saving our data. The function starts by setting the scene in a literal sense. The canvas function initializes a 3D rendered space that visualizes the simulation. Next, spheres are created using the list of bodies, and the dictionaries within for all the necessary visual features like position, color, etc. The spheres will also have a trail to help visualize the object's path. Next, we define the initial time, and timestep in years. Every timestep is 0.365 Earth days. or 0.001 Earth years. The simulation lasts for 10 years to generate a lengthy data set with repeated earth orbits. I believed it would help in model training compared to the initial one year I tried before, and the model displayed some attempt at maintaining the orbits. The storage list for the data is also defined. \n",
    "Next, we gather the initial accelerations using the compute_accelerations function defined earlier. These will be used in the leapfrog integrator.  \n",
    "\n",
    "Finally we compute the half-step velocities of each of the celestial bodies to prep for leapfrog integration, the for loop here goes over every body in the list, providing both the index 'i' and dictionary 'b'. The half step calculation is given by ... tbc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4400610-ef10-4f90-8774-7caf67d7d684",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Main simulation loop\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mt\u001b[49m \u001b[38;5;241m<\u001b[39m simulation_duration:\n\u001b[0;32m      3\u001b[0m     rate(\u001b[38;5;241m200\u001b[39m)  \u001b[38;5;66;03m# Limit to 200 frames per second\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Save current timestep data incrementally\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # Main simulation loop\n",
    "    while t < simulation_duration:\n",
    "        rate(200)  # Limit to 200 frames per second\n",
    "        \n",
    "        # Save current timestep data incrementally\n",
    "        save_data_incremental(t, bodies)\n",
    "        \n",
    "        # Update positions of all bodies using v_half\n",
    "        for i, b in enumerate(bodies):\n",
    "            # new_r = r + v_half * h\n",
    "            b['pos'] = b['pos'] + b['v_half'] * h\n",
    "        \n",
    "        # Compute new accelerations after moving bodies\n",
    "        accels = compute_accelerations(bodies)\n",
    "        \n",
    "        # Update velocities for all bodies\n",
    "        for i, b in enumerate(bodies):\n",
    "            # new_v_half = v_half + a * h\n",
    "            b['v_half'] = b['v_half'] + accels[i] * h\n",
    "            \n",
    "            # Update the sphere positions in the scene\n",
    "            b['obj'].pos = b['pos']\n",
    "        \n",
    "        t += h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25e23a-495f-40be-ba78-0bf9a6036d9a",
   "metadata": {},
   "source": [
    "The rest of the simulation function resides in this while loop. It uses our save_data_incremental() funtion defined earlier to save data at that time step, then utilizes the other equations of leapfrog integration shown in the previous block of text to compute the necessary information for the next time step, all while updating the proper variables. \n",
    "The simulation lasts up until the time duration, through the run time and after saving data the program uses another loop ... tbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddac25-8e1c-442c-befa-72d5e7e41bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb34828-c0d4-496c-bd5e-4a7ec3bb6815",
   "metadata": {},
   "source": [
    "### Section 2, Second Script: PINN Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5fb27-a2a6-4d52-9618-815d780768fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Import PyTorch library for building and training the neural network.\n",
    "from torch.utils.data import Dataset, DataLoader  # Utilities for dataset handling and batching.\n",
    "import pandas as pd  # Pandas for data manipulation and analysis.\n",
    "import numpy as np  \n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1fd52-edeb-4ecd-a9ef-b84c8a6341aa",
   "metadata": {},
   "source": [
    "These are the modules and functions I've called for my script. PyTorch or 'torch' is the center of my script, its a framework for developing neural networks. Dataset and DataLoader from torch.utils.data are necessary for properly batching the data for my model. Pandas also assists in data preprocessing as its used for file manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12780944-4061-4fa7-8080-918fc57f6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for Solar System Simulation Data \n",
    "class SolarSystemDataset(Dataset):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734ec45-35b4-414d-85f1-7fad82b3ab2c",
   "metadata": {},
   "source": [
    "This inherits from torch.utils.data.dataset class, and is used so that we can easily work with PyTorch's data loading utilities, allowing for efficient data batching, shuffling and parallel processing.\n",
    "\n",
    "Data batching is the process of grouping multiple samples in a single \"batch\" before \"feeding\" to a neural network for training. Modern CPUs and GPUs are optimized for parallel computations, batching allows the use of vectorized operations, which help speed up processing over individual samples. \n",
    "\n",
    "Data shuffling is the random rearrangement of data samples before a training epoch occurs.\n",
    "\n",
    "Parallel processing is the use of multiple worker processes or threads to load and preprocess data at once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea05ab-dc7f-433e-a508-9f1bf2caca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Initialize the dataset by loading data from a CSV file.\n",
    "    #csv_file: Path to the CSV file containing simulation data.\n",
    "    def __init__(self, csv_file):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b187990-4edf-4921-9d81-553ee75a1259",
   "metadata": {},
   "source": [
    "The role of this function is to initialize the the attributes of the current class instance and conduct and setup processes before the object is used. This is the basis for the \"Constructor\" method for Python classes. \n",
    "\n",
    "'self' refers to the instance of the class itself, and allows access to the attributes of the class. \n",
    "\n",
    "Any other argument in this line equates to the required inputs to initialize the object, in this instance (pun) its the csv_file made in the previous script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d6ad4-1a5e-46a9-acb3-acbd9bb403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Load the data from the CSV file into the Dataframe using Panads.\n",
    "        self.data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748a3a0-200d-4ca1-8fee-17a379e67d33",
   "metadata": {},
   "source": [
    "This line uses pandas 'pd' to load the data from the csv_file using the 'read_csv' function and placed into the dataframe as instance attribute self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dac52-4648-480d-8d12-4bf47fcb5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def __len__(self):\n",
    "       \n",
    "        # Return the total number of samples in the dataset.\n",
    "        \n",
    "        # Using length-1 because I need a \"next state\" for each sample.\n",
    "        return len(self.data) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c9d17-d99b-4c78-8704-970382828ec3",
   "metadata": {},
   "source": [
    "The '_ len__' method returns the total number of samples in a dataset. I used it as 'len(self.data) - 1' because I needed to verify that each sample in the dataframe has a 'current state' and 'next state' pairing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655682bd-8457-4dcb-9b71-4fb7b2340c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Current state (all columns except time in column 0).\n",
    "        current_state = self.data.iloc[idx, 1:].values.astype(np.float32)\n",
    "        \n",
    "        # Next state (the next row in the dataset).\n",
    "        next_state = self.data.iloc[idx + 1, 1:].values.astype(np.float32)\n",
    "\n",
    "        return torch.tensor(current_state), torch.tensor(next_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e822d7-bf45-457c-829c-9ff32c8caaec",
   "metadata": {},
   "source": [
    "The purpose of this getitem method is to capture instances of my dataset class and index '[]'  them as individual samples based on an index. This will allow efficient data access and manipulation during training. The first line takes the data, column 1,  at a specified location of that indexed instance, row 'idx', and stores it in that variable, current_state, as a lengthy float to capture the minor variations between states. Next_state is essentially the exact same as current_state, with a tweak to capture the data for the next instance. \n",
    "\n",
    "Finally, the numpy arrays are converted and returned as torch tensors. These tensors are crucial when working with PyTorch structures as they're optimized for GPU acceleration and automatic differentiation. \n",
    "\n",
    "Next, we'll define the PINN class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e532737-9e3c-46f2-bb86-a7e07a1b3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network \n",
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers=3, hidden_units=128):\n",
    "                \n",
    "        super(PINN, self).__init__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a7a7-f02c-4ac0-a776-489623265afe",
   "metadata": {},
   "source": [
    "Here, we define the Physics Informed Neural Network, the PINN class. PINNs integrate physical laws and equations into the training process, which should allow the model to get a better grasp of orbital mechanics in my case. \n",
    "\n",
    "'torch.nn.module' serves as the base class for all neural networks, and is essentially what kept me from starting entirely from scratch when switching from an LSTM model to a GNN, now to a PINN. By inheriting from this class, the model gains essential functions like parameter management, the functionality to move to different devices (CPU/GPU), and the forward pass function that I use later on. \n",
    "\n",
    "The constructor method for this class is defined, this time with many more parameters. 'Input_size' refers to the dimensions of the data going into the model for training, in this case its position in 3D space (x, y, z), plus the velocities in 3D space (vx, vy, vz) times the number of bodies we want to predict (Sun, Earth, Jupiter, so 3). In our system it is 18. \n",
    "\n",
    "(Important note, this is the only non-automatic aspect to adding more bodies, that model's parameters. However it is basic math and just changing the value)\n",
    "\n",
    "Output_size mirrors input_size as we want to guess the next state, so also 18. \n",
    "\n",
    "hidden units, the number of neurons hidden in each layer, retains its default value of 128. This number affects the model's learning capacity and computational efficiency, and because it works it remains unchanged. \n",
    "\n",
    "The 'super' function initializes the parent torch.nn.module class, and is crucial for setting up parameter tracking and device placement from PyTorch modules.\n",
    "\n",
    "Next, the layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509472a-bb69-4058-a4e7-c7dbf6afe191",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Layers of the model\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_units))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(torch.nn.Linear(hidden_units, hidden_units))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_units, output_size))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5eeded-60e3-4622-a6f5-76c2a87bb045",
   "metadata": {},
   "source": [
    "First we initialize an empty list to store the layers of the neural network using 'layers = []'\n",
    "\n",
    "The torch.nn.Linear function creates a linear, fully connected layer that in this case maps input features to the first hidden layer, this is appended to layers. The linear transformation of this process looks like \n",
    "\n",
    "$$y = xA^T + b$$\n",
    "\n",
    "with $A$ being the weight matrix and $b$ the bias vector. \n",
    "\n",
    "torch.nn.ReLU() adds a Rectified Linear Unit activation function that introduces nonlinearity into the model, allowing the learning of complex patterns and odd trajectories. This also gets appended into layers. \n",
    "\n",
    "The for loop iterates as many times as there are hidden layers. The contents of the loop connects one hidden layer to the next, creating a map of connected hidden layers based off the number of hidden units in each layer. In this case every hidden layer has the same amount of hidden units.\n",
    "\n",
    "This along with the applied ReLU function get appended to layers. \n",
    "\n",
    "Next, the final fully connected layer connecting the last hidden layer to the output layer is created, and appended. \n",
    "\n",
    "torch.nn.Sequential chains the list of layers into a single sequential model. *layers unpacks the list passing each layer as a separate argument, resulting in the newly built neural network model, self.model, as a sequential container that applies each layer when data gets passed through.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d00000-9af8-4b8c-818a-600ae5a69f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x):\n",
    "        \n",
    "        #Forward pass through the network.\n",
    "        # x: Input tensor (current state).\n",
    "        # return: Output tensor (predicted next state).\n",
    "        \n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca332e6d-8780-4142-bd19-39112b11f02d",
   "metadata": {},
   "source": [
    "Here we define the forward pass of the neural network. It returns our model as a function, self.model(x), that passes input 'x' through its sequentially defined layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521cc274-13ae-40b1-ae01-686757f38d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2718886.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def compute_loss(predictions, targets, positions, velocities, masses, G=4*(np.pi**2), Δt=0.001):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d75b1a-b68f-4efa-9135-d45a445d8b7f",
   "metadata": {},
   "source": [
    "This function is integral to the design of my PINN model setup, here we add in the equations of motion that make up the physics aspect to the model's training regimen, allowing it to hopefully get a glimmer of understanding of orbital dynamics. The arguments are as follows\n",
    "\n",
    "'predictions' is a PyTorch tensor, its the generated output given to us by the model and provides the predicted positions and velocities at the next time step. \n",
    "\n",
    "'targets' is also a PyTorch tensor that contains the actual next state of the system based on the simulation we ran in the previous script. \n",
    "\n",
    "'positions' another involved tensor, it contains the spatial data at a given time step.\n",
    "\n",
    "'velocities' similar to 'positions', a tensor that contains the velocities at a given timestep.\n",
    "\n",
    "'masses' a tensor of constants, its in tensor format to simplify training processes. \n",
    "\n",
    "'G' is the gravitational constant set to 4$\\pi^2$ to remain consistent with the previous script. \n",
    "\n",
    "'Δt' is the time step according to 'h' in the previous script. Consistency is key to making this project work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff31d7-a2dd-44ba-b598-7159f15350c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    data_loss = torch.nn.functional.mse_loss(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a4223-405a-48e6-b576-d4725cc43943",
   "metadata": {},
   "source": [
    "torch.nn.functional.mse_loss computes the Mean Squared Error between the predictions and target data, this encourages the model to produce outputs closer to the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c19121-b720-407b-8865-0fb815c2f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    batch_size, total_features = predictions.shape\n",
    "    num_bodies = total_features // 6  # each body: 3 pos + 3 vel\n",
    "    pos_dim = num_bodies * 3\n",
    "    vel_dim = num_bodies * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8038595-546f-4975-b051-7db71311f5ba",
   "metadata": {},
   "source": [
    "the batch size refers to the number of samples in the current batch, and the total_features is the total number of features per sample. Both make up the shape of the current prediction.\n",
    "We get num_bodies by dividing the number of total_features (18) by 6 (3 for position coordinates, 3 for velocity components.) \n",
    "pos_dim and vel_dim refer to the number of dimensions (features) each metric has (3 each). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4215c-9788-4cae-8fd0-22dd98d819f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Extract predicted positions and velocities\n",
    "    predicted_positions = predictions[:, :pos_dim]\n",
    "    predicted_velocities = predictions[:, pos_dim:pos_dim+vel_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3483f3-b998-47fa-981e-d53f67e6487c",
   "metadata": {},
   "source": [
    "predicted_positions selects the rows in the batch and columns from the start up to 'pos_dim', and represents the predicted positions of all celestial bodies. \n",
    "\n",
    "predicted_velocities selects the rows in the batch and columns from 'pos_dim' up until 'pos_dim + vel_dim', and represents the predicted velocities for all celestial bodies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ed505-3fca-4861-b3c4-a54e312fbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    predicted_accelerations = (predicted_velocities - velocities) / Δt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2105f-ce21-4ac1-bd5c-b56e4ebb1b51",
   "metadata": {},
   "source": [
    "This line computes the change in velocity over time step Δt, and predicted_accelerations represent the model's estimated changes in velocites based off the predicted velocities. This assumes $$a = \\frac{Δv}{Δt} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20472030-2b1a-48c9-b96f-6e8950b5200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    physics_loss = 0.0\n",
    "    for i in range(num_bodies):\n",
    "        force_residual = torch.zeros_like(predicted_positions[:, i*3:(i+1)*3])\n",
    "        for j in range(num_bodies):\n",
    "            if i != j:\n",
    "                r_ij = positions[:, i*3:(i+1)*3] - positions[:, j*3:(j+1)*3]\n",
    "                # Clamping the distance to a minimum of 1 to avoid huge forces exploding the training loss. (Had happened.)\n",
    "                dist = torch.clamp(torch.norm(r_ij, dim=1, keepdim=True), 1)\n",
    "                force = -G * masses[j] * r_ij / (dist**3)\n",
    "             \n",
    "                force_residual += force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525ff05-5850-4fcd-937a-a0731e4c19b5",
   "metadata": {},
   "source": [
    "'physics_loss = 0.0' initializes the physics loss variable to soon hold all physics based loss across all bodies in a batch. \n",
    "\n",
    "The for loop iterates over each body to capture the loss data.\n",
    "force_residual initializes with a tensor of zeros with the same shape as the position vector of the ith body with the goal of accumulating the gravitational forces exerted on the ith body by the rest of the bodies. Seems similar to something we did earlier because it is, however this time we use torch tensors for simplified communication with the model. \n",
    "\n",
    "the for j loop iterates all bodies to capture the gravitational force of all bodies acting on the ith body, and prevent ith on ith interactions using the != condition check. \n",
    "\n",
    "As before, r_ij represents the vector displacement from the jth body to the ith body. \n",
    "\n",
    "torch.norm(r_ij, dim = 1, keepdim = True) calculates the Euclidean distance between the ith and jth bodies, and torch.clamp(..., 1) is used in this case to restrict the minimum distance to 1 AU to prevent the bodies from approaching the sun too closely and exploding the loss values. For the inclusion of Venus and Mercury this should be changed to their respective distances as minimums, but for simplicity we'll keep it at Earth's 1 AU. We then use Newton's law of gravitation to calculate the force and accumulate the result into force_residual. \n",
    "\n",
    "Any other physical interactions should be included in this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7120eea-742b-4ea7-85ad-e4177001f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # Compute physics loss for body i\n",
    "        physics_loss += torch.mean((predicted_accelerations[:, i*3:(i+1)*3] - force_residual)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa082f-9a83-43ef-a100-425429abe3ba",
   "metadata": {},
   "source": [
    "Working from in heading out, 'predicted_accelerations[:, i*3:(i+1)*3] - force_residual)**2' represents the squared difference between the model's predicted acceleration and teh physically computed acceleration based on gravitational forces. When compared to actual astronomical data there should be differences based on the interactions not included abnove, but since this section and the simulation primarily only focus on the gravitational interaction, it should work out for what I need. \n",
    "\n",
    "torch.mean computes the mean squared error for all samples in the batch for the ith body's acceleration. \n",
    "\n",
    "This gets accumulated into physics_loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db99d81-2afe-4c24-ad04-5431533f2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    physics_loss = physics_loss / num_bodies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3828ed9-690b-43cc-8060-5966547aeeb3",
   "metadata": {},
   "source": [
    "Normalizes the physics loss across all bodies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e60c75-0d66-4d0a-b49b-2309704af78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return data_loss, physics_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bfd109-c307-4a41-9a13-120decb9a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loss is the MSE between the model's predictions and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1844f-e30b-4626-b538-860b5b631650",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set working directory\n",
    "    os.chdir(\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92127-f6ac-4ff2-82f3-5168e7d95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # CSV file path\n",
    "    csv_file = \"simulation_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a6219-ce69-4578-8558-433edbdaac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize dataset\n",
    "    dataset = SolarSystemDataset(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749b404-5790-4a0f-8412-7b0b0722cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84768e4-2609-445b-b9ad-c9fcf84c9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split dataset into training (80%) and validation (20%)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06647fd-1e7a-450e-ba59-a3d7a9f95ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141865f9-4660-470d-be93-c1b9c26cbea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af08896-71c5-49fa-bd2a-7de95609a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79812a-b2a1-4258-af07-3082cb3f24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Determine input/output size\n",
    "    sample_input, sample_target = dataset[0]\n",
    "    input_size = len(sample_input)\n",
    "    output_size = len(sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad461a-5d84-4e7d-be1e-850041b8a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35948b-f109-4b20-96fe-f3fcdc917f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize model\n",
    "    model = PINN(input_size, output_size)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7011a8e-99d0-471a-b96f-45b5c3ff9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3aaec6-2d60-4aab-9c7e-4f36716ed5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5) #Adjust Learning Rate Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1181c-2f48-4cb9-bcc4-5ae806dd7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c767c93-d893-4ceb-84e1-6e7f4b69d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Training parameters\n",
    "    epochs = 200\n",
    "    masses = torch.tensor([1.0, 3.004e-6, 9.551e-4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d01ef-e269-4450-8728-50b61e3c2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba254f6-63a4-425a-b71c-05782e5e9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Physics introduction parameters\n",
    "    start_physics_epoch = 10\n",
    "    max_physics_weight = 1e-4 #Adjust weight of physics laws on training here. 0 physics creates the BlackBox model. \n",
    "    physics_weight = 0.0 # Initial physics weight, allows the model to get a grasp of the data and adjust smoother.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262affac-f31b-4e8e-9a73-2a65da1f7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a6420-6e6c-4ed1-b5f4-a15a25c7514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "\n",
    "        # After start_physics_epoch, gradually increase physics weight\n",
    "        if epoch > start_physics_epoch:\n",
    "            physics_weight = (epoch - start_physics_epoch) * (max_physics_weight / 10.0)\n",
    "            physics_weight = min(physics_weight, max_physics_weight)\n",
    "        else:\n",
    "            physics_weight = 0.0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            current_state, next_state = batch\n",
    "\n",
    "            num_bodies = input_size // 6\n",
    "            pos_dim = num_bodies * 3\n",
    "            vel_dim = num_bodies * 3\n",
    "\n",
    "            positions = current_state[:, :pos_dim]\n",
    "            velocities = current_state[:, pos_dim:pos_dim+vel_dim]\n",
    "\n",
    "            predictions = model(current_state)\n",
    "\n",
    "            data_loss, physics_loss = compute_loss(predictions, next_state, positions, velocities, masses)\n",
    "\n",
    "            total_loss = data_loss + physics_weight * physics_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_sum += total_loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss_sum / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                current_state, next_state = batch\n",
    "                positions = current_state[:, :pos_dim]\n",
    "                velocities = current_state[:, pos_dim:pos_dim+vel_dim]\n",
    "                predictions = model(current_state)\n",
    "                data_loss_val, physics_loss_val = compute_loss(predictions, next_state, positions, velocities, masses)\n",
    "                val_total_loss = data_loss_val + physics_weight * physics_loss_val\n",
    "                val_loss_sum += val_total_loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss_sum / len(val_loader)\n",
    "        \n",
    "        #print function to visualize progress. (Fun tidbit. Losses once began in the octillions because I added a safeguard against division by 0. All I had to do was let the model know those columns were supposed to be 0 entirely)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Physics Weight: {physics_weight:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ab4a6-04f7-42d5-b3ec-887feaf093e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc5058-eb8c-45c5-af88-61b3accd8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Save the trained model to my usual directory\n",
    "    model_save_path = os.path.join(\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\", \"PINN_model.pth\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83e25f-0221-4e60-a406-ffceed62e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8cd46-81de-4777-8d2b-7fedc4c2cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546b4ea-301e-4395-a468-86c2c4ba9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77ac3d-50b5-49ce-b231-2f3dc0af5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636dfc6-c864-432e-bdad-b92e25adb6fb",
   "metadata": {},
   "source": [
    "### Section 3, Third Script: Prediction Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e412304-2eab-41ea-ad3a-2bc92b51f778",
   "metadata": {},
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93319687-aed1-4f62-9fb2-675a779286e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vector, sphere, canvas, rate, textures, color\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from vpython import vector, sphere, canvas, rate, textures, color\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5f479-34a5-4e66-9402-e0adda4ba172",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57317ef8-e953-417e-b57c-30ecbbb71567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers=3, hidden_units=128):\n",
    "        \n",
    "        #Initialize the PINN model\n",
    "        #input_size: Number of input features (positions and velocities).\n",
    "        #output_size: Number of output features (positions and velocities).\n",
    "        #hidden_layers: Number of hidden layers in the neural network.\n",
    "        #hidden_units: Number of neurons per hidden layer.\n",
    "        \n",
    "        super(PINN, self).__init__()\n",
    "\n",
    "        # Layers of the model\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_units))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(torch.nn.Linear(hidden_units, hidden_units))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_units, output_size))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167f360-5068-4fde-a012-b4c6afac36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153901cc-6552-48db-8c6b-052acff48be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Forward pass through the network.\n",
    "        #Input tensor (current state).\n",
    "        #Output tensor (predicted next state).\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fd2d5-a846-4309-985a-5377b9d7f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019623e-fb07-416b-9940-64ec0deb7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = [   #Can add others if others are available. Match with sim info.\n",
    "    {\n",
    "        'name': 'Sun',\n",
    "        'mass': 1.0,\n",
    "        'pos': vector(0, 0, 0),\n",
    "        'vel': vector(0, 0, 0),\n",
    "        'radius': 0.2,\n",
    "        'color': color.yellow,\n",
    "        'texture': None,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Earth',\n",
    "        'mass': 3.0e-6,\n",
    "        'pos': vector(1.0, 0, 0),  \n",
    "        'vel': vector(0, 0, -6.179),  \n",
    "        'radius': 0.1,\n",
    "        'color': color.white,\n",
    "        'texture': textures.earth,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Jupiter',\n",
    "        'mass': 9.5e-4,\n",
    "        'pos': vector(5.2, 0, 0),  \n",
    "        'vel': vector(0, 0, -2.624),  \n",
    "        'radius': 0.15,\n",
    "        'color': color.orange,\n",
    "        'texture': None,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8489056-f614-45ff-98e6-df163ddb965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9417be-3383-474f-a0a0-22c41317d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \n",
    "    # Load the pre-trained PINN model from a .pth file.\n",
    "    \n",
    "    # Define the model architecture (ensure this matches the training script)\n",
    "    input_size = 18  # Update this to match your dataset's input size\n",
    "    output_size = 18  # Update this to match your dataset's output size\n",
    "    model = PINN(input_size=input_size, output_size=output_size, hidden_layers=3, hidden_units=128)\n",
    "\n",
    "    # Load the state dictionary\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663032a-fcb5-4a54-880d-f0b9670cca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edff8d-4a58-406d-a3a1-14e55521c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_vector(bodies):\n",
    "   \n",
    "    # Construct the state vector (positions and velocities) from the list of bodies.\n",
    "    # Order: [x,y,z,vx,vy,vz] for each body in the order they are listed in 'bodies'.\n",
    "    \n",
    "    state = []\n",
    "    for b in bodies:\n",
    "        state.append(b['pos'].x)\n",
    "        state.append(b['pos'].y)\n",
    "        state.append(b['pos'].z)\n",
    "        state.append(b['vel'].x)\n",
    "        state.append(b['vel'].y)\n",
    "        state.append(b['vel'].z)\n",
    "    return torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # shape [1, features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417b7e7-4011-4004-bf91-7ddf76160e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5e552-891b-41a2-9151-243e3ab03e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bodies_from_state(bodies, state):\n",
    "   \n",
    "    # Update the positions and velocities of the bodies from the given state vector.\n",
    "    # state is a torch tensor of shape [1, total_features], same order as get_state_vector.\n",
    "    \n",
    "    state = state.squeeze(0).detach().numpy()  # convert to numpy, shape [features]\n",
    "    num_bodies = len(bodies)\n",
    "    for i, b in enumerate(bodies):\n",
    "        idx = i * 6\n",
    "        b['pos'].x = state[idx]\n",
    "        b['pos'].y = state[idx+1]\n",
    "        b['pos'].z = state[idx+2]\n",
    "        b['vel'].x = state[idx+3]\n",
    "        b['vel'].y = state[idx+4]\n",
    "        b['vel'].z = state[idx+5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf314e-42eb-41b8-b572-d415d6d3f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b099a-8065-4558-b871-33fd268b8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    # Set the working directory to where model and data are located\n",
    "    os.chdir(\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc0964-2a2e-4db2-a741-c93fec8b0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e224f-0261-4aeb-a482-7294faeb7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Load the trained model\n",
    "    model_path = \"PINN_model.pth\"\n",
    "    model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48bef8-d9f6-49ed-a5ae-429155787350",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79611753-6b41-429d-bfe1-26c8fe1ac823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create the scene\n",
    "    scene = canvas(title=\"N-Body Simulation (Model Predicted)\", width=800, height=600)\n",
    "    scene.autoscale = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1523bed-a30d-4ac7-bf72-ed8fe4322b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620dbc8d-6684-4c11-919f-f981be7b377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create spheres for each body for visualization\n",
    "    for b in bodies:\n",
    "        b['obj'] = sphere(\n",
    "            pos=b['pos'],\n",
    "            radius=b['radius'],\n",
    "            color=b['color'],\n",
    "            texture=b['texture'],\n",
    "            make_trail=True,\n",
    "            retain=5000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50258e-786d-41e2-b3a2-3461d208625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c14e7-e7ca-4163-a554-6e0b03756962",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Time parameters\n",
    "    t = 0.0        # Start time\n",
    "    h = 0.001       # Timestep in years\n",
    "    simulation_duration = 1.0  # total simulation time in years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c7c37-01da-4e67-8272-ddd696928d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694b0cb-5d7b-4bc6-9d97-642394382f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    while t < simulation_duration:\n",
    "        rate(200)  # 200 frames per second\n",
    "\n",
    "        # Get current state\n",
    "        current_state = get_state_vector(bodies)\n",
    "\n",
    "        # Use the model to predict the next state\n",
    "        # The model should output the next positions and velocities after 1 timestep\n",
    "        predictions = model(current_state)\n",
    "\n",
    "        # Update bodies from the predicted next state\n",
    "        update_bodies_from_state(bodies, predictions)\n",
    "\n",
    "        # Update the sphere positions in the scene\n",
    "        for b in bodies:\n",
    "            b['obj'].pos = b['pos']\n",
    "\n",
    "        t += h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b62e23-af36-428a-b5f4-2e7cc68262cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05782b-fbd9-4ff7-a6fb-e3d1dfd59ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0894a-1201-4f4a-8f08-bac1a470c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951499f3-2609-48d6-b4c8-2bb2f817c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
