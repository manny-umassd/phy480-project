{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000afa7b-a065-445d-a941-8c2d1f14b00e",
   "metadata": {},
   "source": [
    "# Orbital Orchestra of the Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a4a51-56b7-40c8-8bd0-81555aa497a6",
   "metadata": {},
   "source": [
    "## Using a Neural Network to Observe the N-Body Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab787b65-3fde-4608-9fb0-f2a158ca6857",
   "metadata": {},
   "source": [
    "### !!! FOREWARNING, READ BEFORE YOU RUN !!!\n",
    "I have not tested the effects of running all three scripts at once using Jupyter, my intent of this document is to be documentation, not the main scripts to run. I highly recommend downloading the scripts, adjusting the filepath to your own selected path in each script, and run them separately. To properly execute script 2 you may need decent hardware, a way to cool your hardware, and plenty of time for running a few thousand training sessions. I hope the exclamations caught your attention. Ignoring my warning is your choice, if you choose to do so you agree to whatever responsibility may come about. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c54e00-c5e3-4b67-8903-6228369754de",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Let's start with how this project originally came to be. Astrophysics is the topic that interests me the most when it comes to physics. When it comes to the cosmos, I can't help but marvel at the size of literally everything, and how everything just seamlessly works together. The way we as people challenge this final frontier of outer space with what we can while only being able to observe just so much of it. I tend to dream of being involved in future missions in some capacity, so much so that I'd think of imaginary flight systems. Thoughts of GPS systems came to mind as well, I learned that they use trilateration to calculate a device's at regular intervals down here on Earth. That thought train ran to how could we implement a GPS system way out there? Rather, how do we keep track of various space objects as they move in various directions along our flight paths? This thought train is what initially led me to choose a project relating to chapter 4 of \"Computational Modeling and Visualization of Physical Systems\", the text written by and provided in Professor Wang's Computational Physics module, where the chapter looks at planetary motion and n-body simulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97d658-82b8-45f9-b6f7-ad4ccc3d5c9c",
   "metadata": {},
   "source": [
    "However, this past summer hit me with a different sort of reality. As I worked on my job search for post-graduation, I received some feedback for my applications. I would not be considered for my lack of AI and machine learning skills. My plan was then to use this project to gain that skill, yet I still wanted to work on an n-body simulation. Hence this topic came to be. I would merge the two and use machine learning to predict orbits, essentially letting me work on that simulation and gain that skill. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccfe1c-df4c-487d-88b0-d4b1f2b665ff",
   "metadata": {},
   "source": [
    "We begin the three-body simulation of the Sun, the Earth, and Jupiter below, a modification of the Earth-Sun system featured in program 4.1 and figure 4.1 of the text. \n",
    "Original modifications included a Python 3.x conversion, updating the format and modules used, and the addition of the rest of the planets in our solar system. For the sake of this project and future model training, all planets except Earth and Jupiter were removed, but their data is stored along with all the scripts made in my github. Since the original modified program contained all planets, please assume these scripts were made with their potential reinclusion in mind. They were, with the process only requiring a pasting from the full planet data library into the 'bodies' dictionary for the desired celestial object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074f03c3-618b-4e59-99f9-c7068bb6800c",
   "metadata": {},
   "source": [
    "### Section 1: N-body Simulation (AKA Solar System Sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2aafd-d76f-436c-aa38-82aec5e74d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from vpython import vector, mag, sphere, canvas, rate, textures, color  #Replaces visual module, used to generate the scene and for vector functions\n",
    "import csv  #Used for saving data in a spreadsheet\n",
    "import os   #Used for file system functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7041c-6875-40a7-a0e0-0e38a8fa9b69",
   "metadata": {},
   "source": [
    "We'll import numpy for numerical functions such as including $\\pi$, and select functions from vpython for work in 3D space.\n",
    "'vector' allows the use of vectors and 'mag' allows the collection of the magnitude of those vectors, which is helpful for tasks like obtaining distances between bodies. 'sphere', 'canvas', 'textures', 'color' were needed to create the 3D visual scene, the objects, and give them color or, solely in Earth's case, a texture. 'rate' allows the controlling of simulation speed. \n",
    "\n",
    "csv was imported so that I could export the data collected on the planetary motion into a spreadsheet that would be used to train my model. OS was imported to use a certain directory throughout all scripts, have files written or data saved or pulled, save the model, retrieve the model. All done through the same directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c150ba-bbb6-44bc-9831-074ff9a9b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = [\n",
    "   {\n",
    "        'name': 'Sun',\n",
    "        'mass': 1.0,  #In solar masses\n",
    "        'pos': vector(0, 0, 0),  #Initial position, in AU\n",
    "        'vel': vector(0, 0, 0),  #Initial velocity, in AU/yr\n",
    "        'radius': 0.2,           #Size of sphere, visual purposes only\n",
    "        'color': color.yellow,\n",
    "        'texture': None,         #Because I wanted Earth to have the Earth texture, all bodies must have this line set to 'none' for how the bodies are called in later. Tedious but aides in simplicity later.  \n",
    "    },\n",
    "    {\n",
    "        'name': 'Earth',\n",
    "        'mass': 3.0e-6,  #In Solar masses\n",
    "        'pos': vector(1.0, 0, 0),  # Distance ~1 AU from the Sun\n",
    "        'vel': vector(0, 0, -6.179),  # Pulled from table in cpms-ch04\n",
    "        'radius': 0.1,             #Visual purposes only\n",
    "        'color': color.white,      #For blank sphere so texture can be the sphere's \"color\"\n",
    "        'texture': textures.earth, #home\n",
    "    },\n",
    "    {\n",
    "        'name': 'Jupiter',   #Chosen for it's large mass. Helps cause of perturbation on the Sun\n",
    "        'mass': 9.5e-4,      #In solar masses. All masses are pulled from the table in cpms-ch04\n",
    "        'pos': vector(5.2, 0, 0),  # Distance ~5.2 AU from the Sun\n",
    "        'vel': vector(0, 0, -2.624),  # Pulled from table in cpms-ch04\n",
    "        'radius': 0.15,\n",
    "        'color': color.orange,\n",
    "        'texture': None,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea284176-2c73-41f4-ace0-3f81cdcc6ae6",
   "metadata": {},
   "source": [
    "Above we create the list of dictionaries for each celestial body. For organization we start with the centermost object and head outward as we descend In the full list, it is the Sun, Mercury, so on up to Pluto. The structure of the dictionary is integral to the scripts. It's the format used in all scripts, and the format that the model must recognize. We start with the 'name' of the body, that will also be used to automate labeling of columns in data collection. Then we have the 'mass' of the objects in terms of Solar masses. These get recalled when working with the equations of motion later on. Moving on to initial positions and velocities, both metrics get stored in a 'vector' vector to be used later on, and their values are pulled from table 4.1, \"Properties of Kepler's orbits of the Planets\" from the text. 'Radius' for each body is an unrealistic number used only to visualize the objects when the scene renders. However, it is also in AU for those who'd wish to know. 'Color' is the color of the sphere when the scene loads, we use white for Earth so that we may view the texture I was picky about in its full glory instead of painting a deep blue over it as I did in my first several runs of the prediction simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68054110-74a4-4963-87ab-9c6c5231acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accelerations(bodies):\n",
    "    \n",
    "    # Initialize a list of accelerations with zero vectors for all mentioned bodies. (Can include others)\n",
    "    accels = [vector(0,0,0) for _ in range(len(bodies))]\n",
    "    \n",
    "    # For each pair of bodies i, j, compute gravitational acceleration contribution\n",
    "    for i in range(len(bodies)):\n",
    "        for j in range(len(bodies)):\n",
    "            if i != j: #loop works as long as the two bodies referenced aren't the same. \n",
    "                # Relative position vector from body j to i\n",
    "                rij = bodies[i]['pos'] - bodies[j]['pos']\n",
    "                dist = mag(rij)\n",
    "                # Acceleration contribution from body j on i, added to list in location for specified body.\n",
    "                accels[i] += -G * bodies[j]['mass'] * rij / (dist**3)\n",
    "    return accels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd2ff2-846c-4075-9f98-eccc3dbc168d",
   "metadata": {},
   "source": [
    "We create a function used to calculate the gravitational acceleration experienced by each body we've specified above by every other body using two 'for' loops and an 'if.. does not equal' loop to verify that we do not match two like bodies (e.g. Earth pulling on Earth, prevents non-physical results and division by zero) yet still captures the interaction of every body on each other. The outer loop goes over each body as the target body, and the inner loop goes over each body as the source of gravitational force exerted on to the target body. Only if body i does not equal body j does the rest of the function run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce78324-0631-4077-b753-d340c156ae54",
   "metadata": {},
   "source": [
    "Once i not equalling j is verified, the function computes the vector pointing from body j to body i and stores the info into 'rij', whose magnitude is computed the next line down. Finally, the acceleration of that body is then added into accels[i] which acts as the total acceleration for that body. \n",
    "Plainly, we need the accelerations as they dictate the changes in velocity as the simulation progresses through time. We use the idea that \n",
    "\n",
    "$$a_i = \\frac{F_{ij}}{m_i} = -G \\frac{m_j}{r^3_{ij}}\\mathbf{r}_{ij}$$\n",
    "\n",
    "Which is aforementioned acceleration added to accels[i]\n",
    "The function finally returns the acceleration for use later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7333cbf-0c27-4540-808e-6558eaaeddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_incremental(t, bodies, filename=\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\\\\simulation_data.csv\"):\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        # Write the header if the file doesn't exist\n",
    "        with open(filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            headers = [\"time\"]\n",
    "            for body in bodies:\n",
    "                #Creates the rest of the header for the .csv file (e.g Sun_x, Mercury_vz) for all bodies in order listed above.\n",
    "                headers.extend([f\"{body['name']}_x\", f\"{body['name']}_y\", f\"{body['name']}_z\",\n",
    "                                f\"{body['name']}_vx\", f\"{body['name']}_vy\", f\"{body['name']}_vz\"])\n",
    "            writer.writerow(headers)\n",
    "\n",
    "    # Append the data row to the csv file\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [t]\n",
    "        for body in bodies:\n",
    "            row.extend([body['pos'].x, body['pos'].y, body['pos'].z,\n",
    "                        body['vel'].x, body['vel'].y, body['vel'].z])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5541d3-8b85-4c01-a609-972ad379265a",
   "metadata": {},
   "source": [
    "This function was designed to save the metric data for each celestial body at every timestep of the simulation and added for the PHY 480 project. It's incremental and not a batch save at the end because initially my original modified sim ran indefinitely and I was working off of that. This method still works for what I needed, and remains unchanged even after introducing an end time to cease simulating. The variables for this function are the time step involved, the 'bodies' list for the bodies' names, position, and velocity data at time. I have thought about adding acceleration data, I think the model might benefit from the extra data, but for the sake of time that will be a future adjustment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df98df10-20c7-4bc2-9a79-248a791557a9",
   "metadata": {},
   "source": [
    "The upper loop creates the header in the event that the file doesn't exist in my specified directory. It first checks with the if not condition to see if the file exists, it does now so this is skipped, but if it didn't we'd move to the next few lines. The open function opens the file in 'W'rite mode after creating it. CSV.writer is a writer object that will convert the inputted data into strings within the file. Finally, the headers are created. The first one is for 'time', and the rest are the position in x, y, z, format then the velocities in vx, vy, vz format for each celestial body in 'bodies'. The second half, lower loop, of the function is similar to the first in structure, with a lack of file check. The second half also does not create headers, it appends the data from the simulation into the columns generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c91c53d-2e88-4030-a7ca-e4f6a525c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    \n",
    "    #Run the N-body simulation using a Leapfrog integrator and visualize it.\n",
    "    \n",
    "    # Create the scene\n",
    "    scene = canvas(title=\"N-Body Simulation\", width=800, height=600)\n",
    "    scene.autoscale = True\n",
    "    \n",
    "    # Create spheres for each body for visualization\n",
    "    for b in bodies:\n",
    "        b['obj'] = sphere(\n",
    "            pos=b['pos'],\n",
    "            radius=b['radius'],\n",
    "            color=b['color'],\n",
    "            texture=b['texture'],\n",
    "            make_trail=True,\n",
    "            retain=5000  # Keep a long trail\n",
    "        )\n",
    "    \n",
    "    # Time parameters\n",
    "    t = 0.0        # Start time\n",
    "    h = 0.001       # Timestep in years\n",
    "    simulation_duration = 10.0  # Total simulation duration in years\n",
    "    data = []       # Storage for simulation data\n",
    "    \n",
    "    # Initial accelerations\n",
    "    accels = compute_accelerations(bodies)\n",
    "    \n",
    "    # Compute half-step velocities for leapfrog integrator\n",
    "    for i, b in enumerate(bodies):\n",
    "        # v_half = v + 0.5 * a * h\n",
    "        b['v_half'] = b['vel'] + 0.5 * accels[i] * h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5860a9-1713-42e3-8868-6bcd3c9e0ecc",
   "metadata": {},
   "source": [
    "The goal of this function is as commented above. Run the simulation using a Leapfrog Integrator and visualize it. Though now we have the added caveat of saving our data. The function starts by setting the scene in a literal sense. The canvas function initializes a 3D rendered space that visualizes the simulation. Next, spheres are created using the list of bodies, and the dictionaries within for all the necessary visual features like position, color, etc. The spheres will also have a trail to help visualize the object's path. Next, we define the initial time, and timestep in years. Every timestep is 0.365 Earth days. or 0.001 Earth years. The simulation lasts for 10 years to generate a lengthy data set with repeated earth orbits. I believed it would help in model training compared to the initial one year I tried before, and the model displayed some attempt at maintaining the orbits. The storage list for the data is also defined. \n",
    "Next, we gather the initial accelerations using the compute_accelerations function defined earlier. These will be used in the leapfrog integrator.  \n",
    "\n",
    "Finally we compute the half-step velocities of each of the celestial bodies to prep for leapfrog integration, the for loop here goes over every body in the list, providing both the index 'i' and dictionary 'b'. The half step calculation is given by ... tbc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4400610-ef10-4f90-8774-7caf67d7d684",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Main simulation loop\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mt\u001b[49m \u001b[38;5;241m<\u001b[39m simulation_duration:\n\u001b[0;32m      3\u001b[0m     rate(\u001b[38;5;241m200\u001b[39m)  \u001b[38;5;66;03m# Limit to 200 frames per second\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Save current timestep data incrementally\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # Main simulation loop\n",
    "    while t < simulation_duration:\n",
    "        rate(200)  # Limit to 200 frames per second\n",
    "        \n",
    "        # Save current timestep data incrementally\n",
    "        save_data_incremental(t, bodies)\n",
    "        \n",
    "        # Update positions of all bodies using v_half\n",
    "        for i, b in enumerate(bodies):\n",
    "            # new_r = r + v_half * h\n",
    "            b['pos'] = b['pos'] + b['v_half'] * h\n",
    "        \n",
    "        # Compute new accelerations after moving bodies\n",
    "        accels = compute_accelerations(bodies)\n",
    "        \n",
    "        # Update velocities for all bodies\n",
    "        for i, b in enumerate(bodies):\n",
    "            # new_v_half = v_half + a * h\n",
    "            b['v_half'] = b['v_half'] + accels[i] * h\n",
    "            \n",
    "            # Update the sphere positions in the scene\n",
    "            b['obj'].pos = b['pos']\n",
    "        \n",
    "        t += h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25e23a-495f-40be-ba78-0bf9a6036d9a",
   "metadata": {},
   "source": [
    "The rest of the simulation function resides in this while loop. It uses our save_data_incremental() funtion defined earlier to save data at that time step, then utilizes the other equations of leapfrog integration shown in the previous block of text to compute the necessary information for the next time step, all while updating the proper variables. \n",
    "The simulation lasts up until the time duration, through the run time and after saving data the program uses another loop ... tbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddac25-8e1c-442c-befa-72d5e7e41bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb34828-c0d4-496c-bd5e-4a7ec3bb6815",
   "metadata": {},
   "source": [
    "### Section 2, Second Script: PINN Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5fb27-a2a6-4d52-9618-815d780768fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Import PyTorch library for building and training the neural network.\n",
    "from torch.utils.data import Dataset, DataLoader  # Utilities for dataset handling and batching.\n",
    "import pandas as pd  # Pandas for data manipulation and analysis.\n",
    "import numpy as np  \n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1fd52-edeb-4ecd-a9ef-b84c8a6341aa",
   "metadata": {},
   "source": [
    "These are the modules and functions I've called for my script. PyTorch or 'torch' is the center of my script, its a framework for developing neural networks. Dataset and DataLoader from torch.utils.data are necessary for properly batching the data for my model. Pandas also assists in data preprocessing as its used for file manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12780944-4061-4fa7-8080-918fc57f6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for Solar System Simulation Data \n",
    "class SolarSystemDataset(Dataset):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734ec45-35b4-414d-85f1-7fad82b3ab2c",
   "metadata": {},
   "source": [
    "This inherits from torch.utils.data.dataset class, and is used so that we can easily work with PyTorch's data loading utilities, allowing for efficient data batching, shuffling and parallel processing.\n",
    "\n",
    "Data batching is the process of grouping multiple samples in a single \"batch\" before \"feeding\" to a neural network for training. \n",
    "\n",
    "Data shuffling is the random rearrangement of data samples before a training epoch occurs.\n",
    "\n",
    "Parallel processing is the use of multiple worker processes or threads to load and preprocess data at once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559594d-6ceb-4eb2-8c89-d7c77596459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea05ab-dc7f-433e-a508-9f1bf2caca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Initialize the dataset by loading data from a CSV file.\n",
    "    #csv_file: Path to the CSV file containing simulation data.\n",
    "    def __init__(self, csv_file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896d0c2-f8cd-4659-9eda-ffc284cdef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d6ad4-1a5e-46a9-acb3-acbd9bb403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Load the data from the CSV file into a Pandas Dataframe.\n",
    "        self.data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9ea0a-7054-4e90-8fce-02bf3c9031ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dac52-4648-480d-8d12-4bf47fcb5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def __len__(self):\n",
    "       \n",
    "        # Return the total number of samples in the dataset.\n",
    "        \n",
    "        # Using length-1 because I need a \"next state\" for each sample.\n",
    "        return len(self.data) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3bd47-9963-4ecf-8388-6a1aa9d1aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655682bd-8457-4dcb-9b71-4fb7b2340c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Retrieve a single sample from the dataset.\n",
    "        # idx: Index of the sample to retrieve.\n",
    "        # return: Input (current state) and target (next state).\n",
    "        \n",
    "        # Current state (all columns except time in column 0).\n",
    "        current_state = self.data.iloc[idx, 1:].values.astype(np.float32)\n",
    "        \n",
    "        # Next state (the next row in the dataset).\n",
    "        next_state = self.data.iloc[idx + 1, 1:].values.astype(np.float32)\n",
    "\n",
    "        return torch.tensor(current_state), torch.tensor(next_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f53c54-dba9-4103-906c-3eafe3cd0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e532737-9e3c-46f2-bb86-a7e07a1b3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network \n",
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers=3, hidden_units=128):\n",
    "        \n",
    "        # Initialize the PINN model.\n",
    "        # input_size: Number of input features (positions and velocities).\n",
    "        # output_size: Number of output features (positions and velocities).\n",
    "        # hidden_layers: Number of hidden layers in the neural network.\n",
    "        # hidden_units: Number of neurons per hidden layer.\n",
    "        \n",
    "        super(PINN, self).__init__()\n",
    "\n",
    "        # Layers of the model\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_units))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(torch.nn.Linear(hidden_units, hidden_units))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_units, output_size))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ea03e-2b46-484e-a9d5-d61b5124e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d00000-9af8-4b8c-818a-600ae5a69f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x):\n",
    "        \n",
    "        #Forward pass through the network.\n",
    "        # x: Input tensor (current state).\n",
    "        # return: Output tensor (predicted next state).\n",
    "        \n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92621d0c-f514-4fde-aa41-3486f5e19656",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521cc274-13ae-40b1-ae01-686757f38d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2718886.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def compute_loss(predictions, targets, positions, velocities, masses, G=4*(np.pi**2), Δt=0.001):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc466117-ee5b-4e4a-8b0f-ac2d611829b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff31d7-a2dd-44ba-b598-7159f15350c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    data_loss = torch.nn.functional.mse_loss(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b2d2d-8f61-4feb-ad3d-1703a3753001",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c19121-b720-407b-8865-0fb815c2f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    batch_size, total_features = predictions.shape\n",
    "    num_bodies = total_features // 6  # each body: 3 pos + 3 vel\n",
    "    pos_dim = num_bodies * 3\n",
    "    vel_dim = num_bodies * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06567-c9b3-48b3-bcba-7319936aebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4215c-9788-4cae-8fd0-22dd98d819f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Extract predicted positions and velocities\n",
    "    predicted_positions = predictions[:, :pos_dim]\n",
    "    predicted_velocities = predictions[:, pos_dim:pos_dim+vel_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa66daa-59d8-46d5-a483-628b4f5c2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ed505-3fca-4861-b3c4-a54e312fbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    predicted_accelerations = (predicted_velocities - velocities) / Δt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648a550-c940-417e-bc34-74bb0005a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20472030-2b1a-48c9-b96f-6e8950b5200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    physics_loss = 0.0\n",
    "    for i in range(num_bodies):\n",
    "        force_residual = torch.zeros_like(predicted_positions[:, i*3:(i+1)*3])\n",
    "        for j in range(num_bodies):\n",
    "            if i != j:\n",
    "                r_ij = positions[:, i*3:(i+1)*3] - positions[:, j*3:(j+1)*3]\n",
    "                # Clamping the distance to a minimum of 1 to avoid huge forces exploding the training loss. (Had happened.)\n",
    "                dist = torch.clamp(torch.norm(r_ij, dim=1, keepdim=True), 1)\n",
    "                force = -G * masses[j] * r_ij / (dist**3)\n",
    "             \n",
    "                force_residual += force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637846e-079e-43e1-9c9b-586bc1b0a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7120eea-742b-4ea7-85ad-e4177001f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # Compute physics loss for body i\n",
    "        physics_loss += torch.mean((predicted_accelerations[:, i*3:(i+1)*3] - force_residual)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4a9d0-7566-4799-984a-44eab8ff032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db99d81-2afe-4c24-ad04-5431533f2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Optional: normalize physics_loss by num_bodies if desired\n",
    "    physics_loss = physics_loss / num_bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3590105-e29a-4bf5-baee-6ef3d2e0b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e60c75-0d66-4d0a-b49b-2309704af78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return data_loss, physics_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bfd109-c307-4a41-9a13-120decb9a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1844f-e30b-4626-b538-860b5b631650",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set working directory\n",
    "    os.chdir(\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92127-f6ac-4ff2-82f3-5168e7d95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # CSV file path\n",
    "    csv_file = \"simulation_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a6219-ce69-4578-8558-433edbdaac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize dataset\n",
    "    dataset = SolarSystemDataset(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749b404-5790-4a0f-8412-7b0b0722cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84768e4-2609-445b-b9ad-c9fcf84c9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split dataset into training (80%) and validation (20%)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06647fd-1e7a-450e-ba59-a3d7a9f95ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141865f9-4660-470d-be93-c1b9c26cbea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af08896-71c5-49fa-bd2a-7de95609a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79812a-b2a1-4258-af07-3082cb3f24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Determine input/output size\n",
    "    sample_input, sample_target = dataset[0]\n",
    "    input_size = len(sample_input)\n",
    "    output_size = len(sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad461a-5d84-4e7d-be1e-850041b8a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35948b-f109-4b20-96fe-f3fcdc917f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize model\n",
    "    model = PINN(input_size, output_size)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7011a8e-99d0-471a-b96f-45b5c3ff9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3aaec6-2d60-4aab-9c7e-4f36716ed5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5) #Adjust Learning Rate Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1181c-2f48-4cb9-bcc4-5ae806dd7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c767c93-d893-4ceb-84e1-6e7f4b69d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Training parameters\n",
    "    epochs = 200\n",
    "    masses = torch.tensor([1.0, 3.004e-6, 9.551e-4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d01ef-e269-4450-8728-50b61e3c2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba254f6-63a4-425a-b71c-05782e5e9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Physics introduction parameters\n",
    "    start_physics_epoch = 10\n",
    "    max_physics_weight = 1e-4 #Adjust weight of physics laws on training here. 0 physics creates the BlackBox model. \n",
    "    physics_weight = 0.0 # Initial physics weight, allows the model to get a grasp of the data and adjust smoother.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262affac-f31b-4e8e-9a73-2a65da1f7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a6420-6e6c-4ed1-b5f4-a15a25c7514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "\n",
    "        # After start_physics_epoch, gradually increase physics weight\n",
    "        if epoch > start_physics_epoch:\n",
    "            physics_weight = (epoch - start_physics_epoch) * (max_physics_weight / 10.0)\n",
    "            physics_weight = min(physics_weight, max_physics_weight)\n",
    "        else:\n",
    "            physics_weight = 0.0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            current_state, next_state = batch\n",
    "\n",
    "            num_bodies = input_size // 6\n",
    "            pos_dim = num_bodies * 3\n",
    "            vel_dim = num_bodies * 3\n",
    "\n",
    "            positions = current_state[:, :pos_dim]\n",
    "            velocities = current_state[:, pos_dim:pos_dim+vel_dim]\n",
    "\n",
    "            predictions = model(current_state)\n",
    "\n",
    "            data_loss, physics_loss = compute_loss(predictions, next_state, positions, velocities, masses)\n",
    "\n",
    "            total_loss = data_loss + physics_weight * physics_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_sum += total_loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss_sum / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                current_state, next_state = batch\n",
    "                positions = current_state[:, :pos_dim]\n",
    "                velocities = current_state[:, pos_dim:pos_dim+vel_dim]\n",
    "                predictions = model(current_state)\n",
    "                data_loss_val, physics_loss_val = compute_loss(predictions, next_state, positions, velocities, masses)\n",
    "                val_total_loss = data_loss_val + physics_weight * physics_loss_val\n",
    "                val_loss_sum += val_total_loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss_sum / len(val_loader)\n",
    "        \n",
    "        #print function to visualize progress. (Fun tidbit. Losses once began in the octillions because I added a safeguard against division by 0. All I had to do was let the model know those columns were supposed to be 0 entirely)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Physics Weight: {physics_weight:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ab4a6-04f7-42d5-b3ec-887feaf093e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc5058-eb8c-45c5-af88-61b3accd8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Save the trained model to my usual directory\n",
    "    model_save_path = os.path.join(\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\", \"PINN_model.pth\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83e25f-0221-4e60-a406-ffceed62e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8cd46-81de-4777-8d2b-7fedc4c2cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546b4ea-301e-4395-a468-86c2c4ba9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77ac3d-50b5-49ce-b231-2f3dc0af5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636dfc6-c864-432e-bdad-b92e25adb6fb",
   "metadata": {},
   "source": [
    "### Section 3, Third Script: Prediction Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e412304-2eab-41ea-ad3a-2bc92b51f778",
   "metadata": {},
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93319687-aed1-4f62-9fb2-675a779286e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vector, sphere, canvas, rate, textures, color\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from vpython import vector, sphere, canvas, rate, textures, color\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5f479-34a5-4e66-9402-e0adda4ba172",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57317ef8-e953-417e-b57c-30ecbbb71567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers=3, hidden_units=128):\n",
    "        \n",
    "        #Initialize the PINN model\n",
    "        #input_size: Number of input features (positions and velocities).\n",
    "        #output_size: Number of output features (positions and velocities).\n",
    "        #hidden_layers: Number of hidden layers in the neural network.\n",
    "        #hidden_units: Number of neurons per hidden layer.\n",
    "        \n",
    "        super(PINN, self).__init__()\n",
    "\n",
    "        # Layers of the model\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_units))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(torch.nn.Linear(hidden_units, hidden_units))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_units, output_size))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167f360-5068-4fde-a012-b4c6afac36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153901cc-6552-48db-8c6b-052acff48be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Forward pass through the network.\n",
    "        #Input tensor (current state).\n",
    "        #Output tensor (predicted next state).\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fd2d5-a846-4309-985a-5377b9d7f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019623e-fb07-416b-9940-64ec0deb7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = [   #Can add others if others are available. Match with sim info.\n",
    "    {\n",
    "        'name': 'Sun',\n",
    "        'mass': 1.0,\n",
    "        'pos': vector(0, 0, 0),\n",
    "        'vel': vector(0, 0, 0),\n",
    "        'radius': 0.2,\n",
    "        'color': color.yellow,\n",
    "        'texture': None,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Earth',\n",
    "        'mass': 3.0e-6,\n",
    "        'pos': vector(1.0, 0, 0),  \n",
    "        'vel': vector(0, 0, -6.179),  \n",
    "        'radius': 0.1,\n",
    "        'color': color.white,\n",
    "        'texture': textures.earth,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Jupiter',\n",
    "        'mass': 9.5e-4,\n",
    "        'pos': vector(5.2, 0, 0),  \n",
    "        'vel': vector(0, 0, -2.624),  \n",
    "        'radius': 0.15,\n",
    "        'color': color.orange,\n",
    "        'texture': None,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8489056-f614-45ff-98e6-df163ddb965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9417be-3383-474f-a0a0-22c41317d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \n",
    "    # Load the pre-trained PINN model from a .pth file.\n",
    "    \n",
    "    # Define the model architecture (ensure this matches the training script)\n",
    "    input_size = 18  # Update this to match your dataset's input size\n",
    "    output_size = 18  # Update this to match your dataset's output size\n",
    "    model = PINN(input_size=input_size, output_size=output_size, hidden_layers=3, hidden_units=128)\n",
    "\n",
    "    # Load the state dictionary\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663032a-fcb5-4a54-880d-f0b9670cca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edff8d-4a58-406d-a3a1-14e55521c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_vector(bodies):\n",
    "   \n",
    "    # Construct the state vector (positions and velocities) from the list of bodies.\n",
    "    # Order: [x,y,z,vx,vy,vz] for each body in the order they are listed in 'bodies'.\n",
    "    \n",
    "    state = []\n",
    "    for b in bodies:\n",
    "        state.append(b['pos'].x)\n",
    "        state.append(b['pos'].y)\n",
    "        state.append(b['pos'].z)\n",
    "        state.append(b['vel'].x)\n",
    "        state.append(b['vel'].y)\n",
    "        state.append(b['vel'].z)\n",
    "    return torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # shape [1, features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417b7e7-4011-4004-bf91-7ddf76160e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5e552-891b-41a2-9151-243e3ab03e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bodies_from_state(bodies, state):\n",
    "   \n",
    "    # Update the positions and velocities of the bodies from the given state vector.\n",
    "    # state is a torch tensor of shape [1, total_features], same order as get_state_vector.\n",
    "    \n",
    "    state = state.squeeze(0).detach().numpy()  # convert to numpy, shape [features]\n",
    "    num_bodies = len(bodies)\n",
    "    for i, b in enumerate(bodies):\n",
    "        idx = i * 6\n",
    "        b['pos'].x = state[idx]\n",
    "        b['pos'].y = state[idx+1]\n",
    "        b['pos'].z = state[idx+2]\n",
    "        b['vel'].x = state[idx+3]\n",
    "        b['vel'].y = state[idx+4]\n",
    "        b['vel'].z = state[idx+5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf314e-42eb-41b8-b572-d415d6d3f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b099a-8065-4558-b871-33fd268b8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    # Set the working directory to where model and data are located\n",
    "    os.chdir(\"C:\\\\Users\\\\Manny Admin\\\\Desktop\\\\New Data\\\\Simulation Pull\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc0964-2a2e-4db2-a741-c93fec8b0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e224f-0261-4aeb-a482-7294faeb7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Load the trained model\n",
    "    model_path = \"PINN_model.pth\"\n",
    "    model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48bef8-d9f6-49ed-a5ae-429155787350",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79611753-6b41-429d-bfe1-26c8fe1ac823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create the scene\n",
    "    scene = canvas(title=\"N-Body Simulation (Model Predicted)\", width=800, height=600)\n",
    "    scene.autoscale = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1523bed-a30d-4ac7-bf72-ed8fe4322b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620dbc8d-6684-4c11-919f-f981be7b377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create spheres for each body for visualization\n",
    "    for b in bodies:\n",
    "        b['obj'] = sphere(\n",
    "            pos=b['pos'],\n",
    "            radius=b['radius'],\n",
    "            color=b['color'],\n",
    "            texture=b['texture'],\n",
    "            make_trail=True,\n",
    "            retain=5000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50258e-786d-41e2-b3a2-3461d208625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c14e7-e7ca-4163-a554-6e0b03756962",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Time parameters\n",
    "    t = 0.0        # Start time\n",
    "    h = 0.001       # Timestep in years\n",
    "    simulation_duration = 1.0  # total simulation time in years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c7c37-01da-4e67-8272-ddd696928d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694b0cb-5d7b-4bc6-9d97-642394382f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    while t < simulation_duration:\n",
    "        rate(200)  # 200 frames per second\n",
    "\n",
    "        # Get current state\n",
    "        current_state = get_state_vector(bodies)\n",
    "\n",
    "        # Use the model to predict the next state\n",
    "        # The model should output the next positions and velocities after 1 timestep\n",
    "        predictions = model(current_state)\n",
    "\n",
    "        # Update bodies from the predicted next state\n",
    "        update_bodies_from_state(bodies, predictions)\n",
    "\n",
    "        # Update the sphere positions in the scene\n",
    "        for b in bodies:\n",
    "            b['obj'].pos = b['pos']\n",
    "\n",
    "        t += h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b62e23-af36-428a-b5f4-2e7cc68262cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05782b-fbd9-4ff7-a6fb-e3d1dfd59ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0894a-1201-4f4a-8f08-bac1a470c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951499f3-2609-48d6-b4c8-2bb2f817c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "Place holder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
